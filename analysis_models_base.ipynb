{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import af2_analysis as af2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_REPPORT = \"Modelling repport XXXX  vs. YYYY\"\n",
    "WORKDIR = 'WORKDIR_FOLDER'\n",
    "CUTOFF_DISTANCE = 0.5\n",
    "MINIMUM_CONTACTS = 5\n",
    "SELECTION1 = \"chainid 0\"\n",
    "SELECTION2 = \"chainid 1 \"\n",
    "CUTOFF_CONTACTS_GRAPH = 20\n",
    "GENERATE_ALL_PAE_SCRIPT = \"~/CNRS2022/dev/AFToolkit/PAE/generate_all_pae.py\"\n",
    "PPTX_TEMPLATE = \"~/CNRS2022/dev/AFToolkit/misc/template_repporting.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "folders = [ f.path for f in os.scandir(\"predictions/\") if f.is_dir() ]\n",
    "for folder in folders: \n",
    "    os.system(f\"python {GENERATE_ALL_PAE_SCRIPT} -s N -f {folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define specific selection for each models, other SELECTION1 and SELECTION2 will apply.\n",
    "# Example : \"ORF2-1-40_TKB1x2\":[\"chainid 0\", \"chainid 1 or chainid 2\"],\n",
    "SELECTION_MDTRAJ = {\n",
    "\n",
    "}\n",
    "\n",
    "# Define specific selection for actif PTM for each models. Otherwise \"A-B\" will apply. Element must be in a list. \n",
    "# Example : \"ORF2-1-40_TKB1x2\":[\"A-B\", \"A-C\"],\n",
    "SELECTION_actifPTM = {\n",
    "\n",
    "}  \n",
    "\n",
    "#DEFINE LABELS For each models Here. if Empty on MOD1_MOD2, the label will be \"MOD1 vs. MOD2\"\n",
    "# Example : \"ORF2-1-40_TKB1x2\": \"$\\mathrm{ORF2}_{1-40}$ vs. $\\mathrm{TKB1}_{\\mathrm{dimer}}$\",\n",
    "labels_models = {\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "#Labels order in the final graph.\n",
    "# Example :\n",
    "# \"ORF2-1-40_TKB1x2\",\n",
    "# \"ORF2cut-1-40_TKB1x2\", \n",
    "labels_order = [\n",
    "\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samuel's tool wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from af_analysis import analysis\n",
    "from af_analysis import docking\n",
    "\n",
    "\n",
    "def plot_single_PAE(data, index, ax=None, cmap = 'bwr'):\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    \n",
    "    json_file = data.df[\"json\"][index]\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    query = data.df.iloc[index][\"query\"]\n",
    "    \n",
    "    borders = data.chain_length[query]\n",
    "    res_max = sum(borders)\n",
    "    \n",
    "    PAE = json_data[\"pae\"]\n",
    "\n",
    "    ax.imshow(PAE, cmap=cmap,\n",
    "        vmin=0.0,\n",
    "        interpolation='nearest',\n",
    "        vmax=30.0,)\n",
    "\n",
    "    ax.hlines(\n",
    "            np.cumsum(borders[:-1]) - 0.5,\n",
    "            xmin=-0.5,\n",
    "            xmax=res_max,\n",
    "            colors=\"black\",\n",
    "        )\n",
    "\n",
    "    ax.vlines(\n",
    "            np.cumsum(borders[:-1]) - 0.5,\n",
    "            ymin=-0.5,\n",
    "            ymax=res_max,\n",
    "            colors=\"black\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(-0.5, res_max - 0.5)\n",
    "    ax.set_ylim(res_max - 0.5, -0.5)\n",
    "\n",
    "    modelNumber = data.df[\"model\"][index]\n",
    "    ax.set_title(f\"Rank {modelNumber}\")\n",
    "    return ax\n",
    "        \n",
    "        \n",
    "        \n",
    "def save_all_PAE(data, save=True):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    for i in range(len(data.df)):\n",
    "        plot_single_PAE(data, i, cmap='bwr', ax=axes[i])\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        plt.savefig(f\"{data.dir}/PAE.png\", dpi=300)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def save_plddt(data, ax=None):\n",
    "    if ax==None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    for i in range(len(data.df)):\n",
    "\n",
    "        query = data.df.iloc[i][\"query\"]\n",
    "        \n",
    "        borders = data.chain_length[query]\n",
    "        res_max = sum(borders)\n",
    "\n",
    "        plddt = data.get_plddt(i)\n",
    "        ax.plot(plddt, label=f\"Model {i}\", linewidth=0.5)\n",
    "        \n",
    "        ax.vlines(\n",
    "                np.cumsum(borders[:-1]) - 0.5,\n",
    "                ymin=-0.5,\n",
    "                ymax=100,\n",
    "                colors=\"black\",\n",
    "            )\n",
    "        \n",
    "        ax.set_ylim(0,100)\n",
    "\n",
    "        #add legend for every plot, on the side\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{data.dir}/plddt.png\", dpi=300)\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_rank(text):\n",
    "    # Use a regular expression to find the rank number in the format \"_rank_XXX_\"\n",
    "    match = re.search(r'_rank_(\\d+)_', text)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Convert the extracted rank to an integer\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_data(workdir):\n",
    "    os.chdir(workdir)\n",
    "\n",
    "    folders = [f for f in glob.glob(\"*\") if os.path.isdir(f)]\n",
    "\n",
    "    print(folders)\n",
    "\n",
    "    errors=[]\n",
    "    list_of_scores=[]\n",
    "    models_list = {}\n",
    "\n",
    "    for model in tqdm(folders):\n",
    "        \n",
    "        try:\n",
    "            data = af2.Data(model+\"/\")\n",
    "        except Exception as e:\n",
    "            errors.append(model)\n",
    "            print(f\"Error occurred for model {model}: {str(e)}\")\n",
    "            continue\n",
    "        print(model)\n",
    "        \n",
    "        try:\n",
    "            analysis.pdockq(data, )\n",
    "        except:\n",
    "            print(\"pdockQ failed\")\n",
    "        try:\n",
    "            analysis.pdockq2(data, )\n",
    "        except:\n",
    "            print(\"pdockq2 failed\")\n",
    "\n",
    "        try:\n",
    "            analysis.mpdockq(data, )\n",
    "        except:\n",
    "            print(\"mpdockq failed\")\n",
    "            \n",
    "        try:\n",
    "            analysis.inter_chain_pae(data, )\n",
    "        except:\n",
    "            print(\"inter_chain_pae failed\")\n",
    "\n",
    "        try:\n",
    "            analysis.LIS_matrix(data, )\n",
    "        except:\n",
    "            print(\"LIS_matrix failed\")\n",
    "\n",
    "        try:\n",
    "            docking.LIS_pep(data, )\n",
    "        except:\n",
    "            print(\"LIS PEP failed\")\n",
    "\n",
    "        if \"rank\" not in data.df.columns:\n",
    "            #add the rank from PDB name in the dataframe\n",
    "            data.df[\"rank\"] = data.df[\"pdb\"].apply(extract_rank)\n",
    "\n",
    "        def add_value(data, column, row, value):\n",
    "            if column not in data.df.columns:\n",
    "                data.df[column] = pd.NA\n",
    "            data.df.at[row, column] = value\n",
    "        \n",
    "        for i in range(len(data.df)):\n",
    "            \n",
    "            json_file = data.df[\"data_file\"][i]\n",
    "            with open(json_file) as f:\n",
    "                json_data = json.load(f)\n",
    "            pae_array = json_data[\"pae\"]\n",
    "\n",
    "            pae_mean = np.mean(pae_array)\n",
    "            plddt = data.get_plddt(i)\n",
    "            plddt_mean = np.mean(plddt)\n",
    "            per_chain_ptm = json_data[\"per_chain_ptm\"]\n",
    "            pairwise_actifptm = json_data[\"pairwise_actifptm\"]\n",
    "            actifptm = json_data[\"actifptm\"]\n",
    "\n",
    "            add_value(data, \"pae_mean\", i, pae_mean)\n",
    "            add_value(data, \"plddt_mean\", i, plddt_mean)\n",
    "            add_value(data, \"per_chain_ptm\", i, per_chain_ptm)\n",
    "            add_value(data, \"pairwise_actifptm\", i, pairwise_actifptm)\n",
    "            add_value(data, \"actifptm\", i, actifptm)\n",
    "\n",
    "            # data.df.at[i, \"pae_mean\"] = pae_mean\n",
    "            # data.df.at[i, \"plddt_mean\"] = plddt_mean\n",
    "            # data.df.at[i, \"per_chain_ptm\"] = per_chain_ptm\n",
    "            # data.df.at[i, \"pairwise_actifptm\"] = pairwise_actifptm\n",
    "            # data.df.at[i, \"actifptm\"] = actifptm\n",
    "\n",
    "            \n",
    "        name = str(data.df.iloc[0][\"query\"])\n",
    "        models_list[name] = data\n",
    "\n",
    "        list_of_scores.append(data.df)\n",
    "    \n",
    "    results = pd.concat(list_of_scores)\n",
    "\n",
    "    return results\n",
    "\n",
    "def re_create_logfile(workdir, logs):\n",
    "    os.chdir(workdir)\n",
    "\n",
    "    folders = [f for f in glob.glob(\"*\") if os.path.isdir(f)]\n",
    "\n",
    "\n",
    "    for model in folders:\n",
    "        if not os.path.exists(f\"{model}/log.txt\"):\n",
    "            with open (f\"{model}/log.txt\", 'w') as logout:\n",
    "                logfound = False\n",
    "                for logfile in logs:\n",
    "                    with open(logfile, 'r') as f:\n",
    "                        loglines = f.readlines()\n",
    "                    for line in loglines:\n",
    "                        if model in line and \"Query\" in line:\n",
    "                            logfound = True\n",
    "                            logout.write(\"2025-01-08 15:48:02,483 Running colabfold 1.5.5 (00de5b40adeec5368906b9f754ccb4212d05c64d)\\n\")\n",
    "                            logout.write(\"2025-01-08 15:48:06,356 Running on GPU\\n\")\n",
    "                            logout.write(\"2025-01-08 15:48:06,847 Found 5 citations for tools or databases\\n\")\n",
    "                            logout.write(line)\n",
    "                        elif \"Query\" in line and logfound:\n",
    "                            logfound = False\n",
    "                            break\n",
    "                        elif logfound:\n",
    "                            logout.write(line)\n",
    "                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(WORKDIR)\n",
    "# Activate only if you have a single log (or multiple) and that you need to recreate one in each model folder (it's important for the model detection by af_analysis pipeline)\n",
    "# \n",
    "# logs=[\n",
    "#     f\"{WORKDIR}/predictions/log_batch1.txt\",\n",
    "#     f\"{WORKDIR}/predictions/log_batch2.txt\",\n",
    "#     f\"{WORKDIR}/predictions/log_batch3.txt\",\n",
    "#     f\"{WORKDIR}/predictions/log_batch4.txt\",\n",
    "\n",
    "# ]\n",
    "# re_create_logfile(f\"{WORKDIR}/predictions\", logs)\n",
    "# os.chdir(WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_all_data(f\"{WORKDIR}/predictions\")\n",
    "results[\"interLIS\"] = results[\"LIS\"].apply(lambda x: np.mean([x[0][1], x[1][0]]))\n",
    "results[\"LIS_average\"] = results.groupby(\"query\")[\"interLIS\"].transform(\"mean\")\n",
    "results[\"LIS_std\"] = results.groupby(\"query\")[\"interLIS\"].transform(\"std\")\n",
    "results.to_excel(\"all_results.xlsx\")\n",
    "results.query(\"rank == 1\").sort_values(by=\"LIS_pep_rec\", ascending=False).to_excel(\"first_ranked_models.xlsx\")\n",
    "results.query(\"rank == 1\").sort_values(by=\"LIS_pep_rec\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def get_residue_label(traj, atom_index, add=0, with_chain = False):\n",
    "    resname = traj.topology.atom(atom_index).residue.name\n",
    "    resid = traj.topology.atom(atom_index).residue.resSeq + add\n",
    "    chain = chr(ord('A') + traj.topology.atom(atom_index).residue.chain.index)\n",
    "    if with_chain:\n",
    "        return f\"{resname}-{resid}-{chain}\"\n",
    "    else:\n",
    "        return f\"{resname} {resid}\"\n",
    "\n",
    "def compute_contacts(pdbs, selection1, selection2, add1, add2, cutoff=0.4, with_chain=False):\n",
    "    traj = md.load(pdbs, top=pdbs[0])\n",
    "\n",
    "    chainA = traj.topology.select(selection1)\n",
    "    chainB = traj.topology.select(selection2)\n",
    "\n",
    "    chainAB = np.concatenate((chainA,chainB))\n",
    "\n",
    "    contactsB = md.compute_neighbors(traj, cutoff, query_indices=chainA, haystack_indices=chainB)\n",
    "    contactsA = md.compute_neighbors(traj, cutoff, query_indices=chainB, haystack_indices=chainA)\n",
    "\n",
    "\n",
    "    contacts_linearB = [item for sublist in contactsB for item in sublist]\n",
    "    contacts_linearA = [item for sublist in contactsA for item in sublist]\n",
    "    contacts_atoms = np.unique(np.concatenate((contacts_linearB, contacts_linearA)))\n",
    "\n",
    "    subtraj = traj.atom_slice(contacts_atoms)\n",
    "\n",
    "    subtraj.save_pdb(\"subtraj.pdb\")\n",
    "\n",
    "    #get the number of chains \n",
    "    nchains = subtraj.top.n_chains\n",
    "\n",
    "\n",
    "\n",
    "    chain1_atoms = subtraj.topology.select(selection1)\n",
    "    chain2_atoms = subtraj.topology.select(selection2)\n",
    "    #parwise combinations of 2 chains\n",
    "    chain1_chain2 = np.array(np.meshgrid(chain1_atoms, chain2_atoms)).T.reshape(-1, 2)\n",
    "    # all_distances = md.compute_contacts(subtraj, contacts='all')\n",
    "    all_distances = md.compute_distances(subtraj, atom_pairs=chain1_chain2)\n",
    "\n",
    "    nframes = all_distances.shape[0]\n",
    "    npair = all_distances.shape[1]\n",
    "\n",
    "    # Create a dictionary to store the shortest distances between residues for each frame\n",
    "    shortest_distances = defaultdict(lambda: defaultdict(lambda: float('inf')))\n",
    "\n",
    "    for i in range(nframes):\n",
    "        for j in range(npair):\n",
    "            dist = all_distances[i, j]\n",
    "            pair = chain1_chain2[j]\n",
    "            res1 = get_residue_label(subtraj, pair[0], add=add1, with_chain=with_chain)\n",
    "            res2 = get_residue_label(subtraj, pair[1], add=add2, with_chain=with_chain)\n",
    "            \n",
    "            # Check if the current distance is shorter than the stored shortest distance for the current frame\n",
    "            if dist < shortest_distances[i][(res1, res2)]:\n",
    "                shortest_distances[i][(res1, res2)] = dist\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a DataFrame with one column per frame\n",
    "    df_shortest_distances = pd.DataFrame(shortest_distances)\n",
    "\n",
    "    # set multilevel index names to \"res1\" and \"res2\"\n",
    "    df_shortest_distances.index.names = [\"res1\", \"res2\"]\n",
    "\n",
    "    return df_shortest_distances\n",
    "\n",
    "def plot_contacts(df, cutoff, outputname=\"output.png\", minimum_contacts=3, xaxis_label=\"selection 1\", yaxis_label=\"selection 2\", title=\"\", vmax=None):\n",
    "\n",
    "    ncol = len(df.columns)\n",
    "    def count_values_below_threshold(row, threshold=0.4):\n",
    "        return (row < threshold).sum()\n",
    "    count_table  = df.apply(lambda x: (x < cutoff).sum(), axis=1).unstack(fill_value=0)\n",
    "\n",
    "    # Trier les colonnes\n",
    "    numeric_part_columns = count_table.columns.to_series().str.extract('(\\d+)').astype(int)\n",
    "    sorted_columns = numeric_part_columns[0].argsort()\n",
    "    count_table = count_table.iloc[:, sorted_columns]\n",
    "\n",
    "    # Trier l'index\n",
    "    numeric_part_index = count_table.index.to_series().str.extract('(\\d+)').astype(int)\n",
    "    sorted_index = numeric_part_index[0].argsort()\n",
    "    count_table = count_table.iloc[sorted_index]\n",
    "\n",
    "    #keep only the values where the number of contacts is > 4\n",
    "    count_table = count_table[count_table >= minimum_contacts].dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    if vmax == None:\n",
    "        vmax = count_table.max().max()\n",
    "    g = sns.heatmap(count_table, cmap=\"Blues\", annot=False,xticklabels=True, yticklabels=True, ax=ax, vmin=0, vmax=vmax)\n",
    "    \n",
    "    #Set xticklabels to display EVERY LABELS\n",
    "    g.set_xticks(np.arange(0.5, len(count_table.columns), 1))\n",
    "    g.set_xlabel(xaxis_label)\n",
    "    g.set_ylabel(yaxis_label)\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment='center', fontsize=8)\n",
    "    \n",
    "    \n",
    "    g.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    g.figure.savefig(outputname)\n",
    "    \n",
    "\n",
    "    return count_table.replace(np.nan,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = results[\"query\"].unique()\n",
    "\n",
    "os.chdir(WORKDIR+\"/predictions\")\n",
    "\n",
    "output_countact_table = {}\n",
    "for model in models_name:\n",
    "    #specific cases\n",
    "    if model in SELECTION_MDTRAJ:\n",
    "        sel1 = SELECTION_MDTRAJ[model][0]\n",
    "        sel2 = SELECTION_MDTRAJ[model][1]\n",
    "    else: \n",
    "        sel1 = SELECTION1\n",
    "        sel2 = SELECTION2\n",
    "\n",
    "    xaxis = model.split(\"_\")[1]\n",
    "    yaxis = model.split(\"_\")[0]\n",
    "\n",
    "    xsplit = xaxis.split(\"-\")\n",
    "    ysplit = yaxis.split(\"-\")\n",
    "\n",
    "    if len(xsplit) > 0:\n",
    "        try:\n",
    "            decalX = int(xsplit[1])-1\n",
    "        except:\n",
    "            decalX = 0\n",
    "    else:\n",
    "        decalX = 0\n",
    "    if len(ysplit) > 0:\n",
    "        try:\n",
    "            decalY = int(ysplit[1])-1\n",
    "        except:\n",
    "            decalY = 0\n",
    "    else:\n",
    "        decalY = 0\n",
    "\n",
    "    pdbs= results.query(\"query == @model\")[\"pdb\"].values\n",
    "\n",
    "\n",
    "    df_shortest_distances = compute_contacts(pdbs, sel1, sel2, decalY, decalX, CUTOFF_DISTANCE, with_chain=False)\n",
    "    ct = plot_contacts(df_shortest_distances, \n",
    "              CUTOFF_DISTANCE,\n",
    "              xaxis_label=xaxis,\n",
    "              yaxis_label=yaxis, \n",
    "              minimum_contacts=MINIMUM_CONTACTS,\n",
    "              title=f\"Number of contacts among the 15 models (minimum contact = {MINIMUM_CONTACTS})\",\n",
    "              outputname=f\"{model}/{model}_contacts.png\",\n",
    "              vmax=15)\n",
    "    output_countact_table[model] = ct\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional graphics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If no definition of specific \n",
    "\n",
    "print(\"Dictionnary for renaming models\")\n",
    "\n",
    "LEAVE_EMPTY = True\n",
    "for model in results[\"query\"].unique():\n",
    "    if LEAVE_EMPTY:\n",
    "        print(f'\"{model}\":\"{model}\"')\n",
    "    else:\n",
    "        print(f'\"{model}\":\"\",')\n",
    "\n",
    "\n",
    "#Take default labels if no user input\n",
    "\n",
    "if len(labels_order) == 0:\n",
    "    labels_order = list(results[\"query\"].unique())\n",
    "labels_models = []\n",
    "if len(labels_models) == 0:\n",
    "    labels_models = {model:model.split(\"_\")[0] + \" vs \" + model.split(\"_\")[1] for model in labels_order}\n",
    "\n",
    "print(\"list for label order\")\n",
    "labels_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\", context=\"paper\", font=\"sans-serif\", font_scale=1.5)\n",
    "\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")\n",
    "\n",
    "############################################\n",
    "# Stripplot of LIS Scores\n",
    "############################################\n",
    "\n",
    "best = results.query(\"rank == 1\")\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "# Map the query names to their new labels\n",
    "results['query_label'] = results['query'].map(labels_models)\n",
    "# Sort according to the custom order by creating a categorical type\n",
    "results['query'] = pd.Categorical(results['query'], categories=labels_order, ordered=True)\n",
    "results = results.sort_values('query')\n",
    "g = sns.stripplot(x=\"query_label\", y=\"interLIS\", data=results, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"LIS scores for each query\", fontsize=16, weight=\"bold\")\n",
    "plt.ylabel(\"LIS score\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/LISscore.png\", dpi=300)\n",
    "\n",
    "############################################\n",
    "# Best models Plot LIST Score (not so interesting anymore)\n",
    "############################################\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "best['query_label'] = best['query'].map(labels_models)\n",
    "best['query'] = pd.Categorical(best['query'], categories=labels_order, ordered=True)\n",
    "best = best.sort_values('query')\n",
    "g = sns.barplot(x=\"query_label\", y=\"interLIS\", data=best, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"Best LIS scores for each query\", fontsize=16, weight=\"bold\")\n",
    "plt.ylabel(\"LIS score\", fontsize=14, weight=\"bold\")\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/best_LISscore.png\", dpi=300)\n",
    "\n",
    "############################################\n",
    "# Number of contact amon all models plot\n",
    "############################################\n",
    "contact_sums = [x.sum(axis=1) for x in output_countact_table.values()]\n",
    "number_of_contact = pd.concat(contact_sums, axis=1).sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(8.1, 10))\n",
    "dataplot = number_of_contact[number_of_contact > CUTOFF_CONTACTS_GRAPH]\n",
    "g = sns.barplot(y=dataplot.index, x=dataplot.values, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(f\"Most interacting ORF2P residues (number of contacts minimum = {CUTOFF_CONTACTS_GRAPH})\", fontsize=16, weight=\"bold\")\n",
    "plt.xlabel(f\"Number of contacts among all models \", fontsize=14, weight=\"bold\")\n",
    "plt.ylabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/AA_best_interacting_residues.png\", dpi=300)\n",
    "\n",
    "############################################\n",
    "#                ACTIF PTM PLOT\n",
    "############################################\n",
    "if len(SELECTION_actifPTM) == 0:\n",
    "    SELECTION_actifPTM = {model: [\"A-B\"] for model in results[\"query\"].unique()}\n",
    "models = results[\"query\"].unique()\n",
    "actifPTM = defaultdict(list)\n",
    "print(len(actifPTM))\n",
    "actifptm_values = []\n",
    "for model in models: \n",
    "    data_model = results.query(\"query == @model\")\n",
    "    for i in range(len(data_model)):\n",
    "        actifPTM_pair = SELECTION_actifPTM[model]\n",
    "        actifptm_values = []\n",
    "        for pair in actifPTM_pair:\n",
    "            actifptm_values.append(data_model.iloc[i][\"pairwise_actifptm\"][pair])\n",
    "            actifPTM[model].append(np.mean(actifptm_values))\n",
    "\n",
    "data = pd.Series(actifPTM)\n",
    "# Sort according to the labels_order\n",
    "data = data[labels_order]\n",
    "\n",
    "data_long = pd.DataFrame([\n",
    "    {\"Model\": key, \"Model_label\": labels_models[key], \"actifPTM\": value} \n",
    "    for key, values in data.items() \n",
    "    for value in values\n",
    "])\n",
    "\n",
    "# Create categorical type for proper ordering\n",
    "data_long['Model'] = pd.Categorical(data_long['Model'], categories=labels_order, ordered=True)\n",
    "data_long = data_long.sort_values('Model')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "# First plot the violin\n",
    "sns.violinplot(x=\"Model_label\", y=\"actifPTM\", data=data_long, ax=ax, \n",
    "               color='lightgray', # Light color for the violin\n",
    "               inner=None)  # No inner box plot\n",
    "\n",
    "# Then add the points on top\n",
    "sns.stripplot(x=\"Model_label\", y=\"actifPTM\", data=data_long, ax=ax, \n",
    "              jitter=True, size=3, \n",
    "              color='black',  # Dark points for contrast\n",
    "              alpha=1)  # Some transparency for overlapping points\n",
    "\n",
    "plt.xticks(rotation=90)\n",
    "plt.title(\"actifPTM scores for each models\", fontsize=16, weight=\"bold\")\n",
    "plt.ylabel(\"actifPTM\", fontsize=18, weight=\"bold\")\n",
    "plt.ylim(0,1)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "plt.xticks(rotation=90, fontsize=16, ha=\"center\")\n",
    "plt.yticks(fontsize=12)\n",
    "plt.xlabel(\"\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/actifPTM.png\", dpi=300)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation of powerpoint repport automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_models_parameters(jsonfile):\n",
    "    with open(jsonfile) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "models_parameters = get_models_parameters(f\"{WORKDIR}/predictions/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt  # For size adjustment\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(WORKDIR)\n",
    "# Create a PowerPoint presentation from a template\n",
    "template_path = PPTX_TEMPLATE  # Specify your template path\n",
    "prs = Presentation(template_path)\n",
    "\n",
    "# Or if you want to set the aspect ratio to 16:9 manually, you can create a blank presentation and set the size\n",
    "# prs = Presentation()\n",
    "# prs.slide_width = Inches(13.33)  # 16:9 ratio width\n",
    "# prs.slide_height = Inches(7.5)   # 16:9 ratio height\n",
    "\n",
    "#Add a title slide\n",
    "\n",
    "\n",
    "def add_title_slide(prs, title_input, subtitle_text):\n",
    "    slide_layout = prs.slide_layouts[0]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    subtitle = slide.placeholders[1]\n",
    "\n",
    "    title.text = title_input\n",
    "    subtitle.text = subtitle_text\n",
    "\n",
    "\n",
    "\n",
    "def add_methodology_slide(prs, models_parameters):\n",
    "    # Create a new slide with a title and content layout\n",
    "    slide_layout = prs.slide_layouts[1]  # Assuming this layout fits your template\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    content = slide.shapes.placeholders[1]\n",
    "\n",
    "\n",
    "    # Set the title\n",
    "    title.text = \"Methodology\"\n",
    "    title.text_frame.paragraphs[0].font.size = Pt(36)  # Set the font size for the title\n",
    "\n",
    "    # Add bullet points with adjustable font size\n",
    "    bullet_points = [\n",
    "        f'ColabFold Version: {models_parameters[\"version\"]} ({models_parameters[\"commit\"]})',\n",
    "        f'AlphaFold Model: {models_parameters[\"model_type\"]}',\n",
    "        f'MSA mode\": {models_parameters[\"msa_mode\"]}',\n",
    "        f'Number of Queries: {models_parameters[\"num_queries\"]}',\n",
    "        f'Number of Models per Query: {models_parameters[\"num_models\"]*models_parameters[\"num_seeds\"]}',\n",
    "        \n",
    "    ]\n",
    "\n",
    "    for point in bullet_points:\n",
    "        p = content.text_frame.add_paragraph()\n",
    "        p.text = point\n",
    "        p.font.size = Pt(20)  # Adjust the font size for bullet points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_pymol_figure(pdbfile, pymolpath=\"/home/thibault/miniconda3/bin/pymol\"):\n",
    "    pdbfile = os.path.basename(pdbfile)\n",
    "    pymolcmd = f'''as cartoon\n",
    "orient\n",
    "spectrum b, rainbow_rev, minimum=10, maximum=90\n",
    "\n",
    "alias raysetting, set ambient, 0.5; set specular, 0; set ray_trace_mode, 1; set ray_trace_gain, 0.01; set antialias,2; set ray_trace_color, black\n",
    "raysetting\n",
    "\n",
    "scene plddt, store\n",
    "png model1_plddt.png, ray=1, width=1080\n",
    "\n",
    "util.cbc\n",
    "scene bychain, store\n",
    "png model1_bychain.png, ray=1, width=1080\n",
    "'''\n",
    "    os.system(f\"{pymolpath} -c {pdbfile} -d '{pymolcmd}'\")\n",
    "\n",
    "    pymol_allfigures_cmd = f'''\n",
    "models = cmd.get_object_list()\n",
    "cmd.alignto(models[0], \"super\")\n",
    "\n",
    "orient\n",
    "util.cbc\n",
    "bgwhite\n",
    "draw 2160\n",
    "png all_models_bychain.png, width=1080\n",
    "'''\n",
    "    os.system(f\"{pymolpath} -c *.pdb -d '{pymol_allfigures_cmd}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_section(prs, title):\n",
    "    slide_layout = prs.slide_layouts[6]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=title\n",
    "\n",
    "def add_notes(slide, notes):\n",
    "    slide.notes_slide.notes_text_frame.text = notes\n",
    "\n",
    "def add_models_result_slide(prs, model_name, results_dataframe):\n",
    "    ## Check all placeholders in the current slide\n",
    "    #for placeholder in slide.placeholders:\n",
    "    #    print(f\"Placeholder index: {placeholder.placeholder_format.idx}, Placeholder type: {placeholder.placeholder_format.type}\")  \n",
    "\n",
    "    slide_layout = prs.slide_layouts[2]\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text = f\"Model {model_name}\"\n",
    "\n",
    "    #Add a picture of the PAE\n",
    "    slide.placeholders[10].insert_picture(\"all_PAE.png\")\n",
    "    slide.placeholders[11].insert_picture(f\"{model}_coverage.png\")\n",
    "    slide.placeholders[12].insert_picture(f\"{model}_plddt.png\")\n",
    "\n",
    "    #Generating pymol figure, if not exist\n",
    "    img_model_plddt = \"model1_plddt.png\"\n",
    "    img_model_bychain = \"model1_bychain.png\"\n",
    "    # Get unique values of the column \"query\"\n",
    "    if not os.path.exists(img_model_plddt) or not os.path.exists(img_model_bychain) or not os.path.exists(\"all_models_bychain.png\"):\n",
    "        try:\n",
    "            pdbfile = results_dataframe.query(\"query == @model_name and rank == 1\")[\"pdb\"].values[0]\n",
    "        except:\n",
    "            print(results_dataframe.query(\"query == @model_name\"))\n",
    "            1/0\n",
    "        generate_pymol_figure(pdbfile)\n",
    "\n",
    "    slide.placeholders[13].insert_picture(img_model_plddt)\n",
    "    slide.placeholders[14].insert_picture(img_model_bychain)\n",
    "\n",
    "    note = \"\"\"DEFINITIONS OF THE METRICS \n",
    "- The pLDDT Score is a confidence score for each residue in the model. It ranges from 0 to 100, where higher scores indicate higher confidence. \n",
    "- The coverage plot shows the number of sequence in the multiple sequence aligment for each amino acid (Higher the better for the modelling). The colors depends sequence idendity. \n",
    "- PAE stands for \"Predicted Aligned Error\". This metric is a measure of the deviation between the predicted model and the experimental structure. Lower values are better. Low values coldspots between residues in chains A and B could indicate potential interaction sites.\n",
    "\"\"\"\n",
    "\n",
    "    add_notes(slide, note)\n",
    "\n",
    "def add_all_models(prs, model_name):\n",
    "    slide_layout = prs.slide_layouts[5]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text = f\"Model {model_name} - All models\"\n",
    "\n",
    "    imgfile = \"all_models_bychain.png\"\n",
    "\n",
    "    slide.placeholders[13].insert_picture(imgfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_slide_interactions(prs):\n",
    "    slide_layout = prs.slide_layouts[3]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=\"Interactions between MSN and other targets\"\n",
    "\n",
    "    figure_LIS = \"figures/actifPTM.png\"\n",
    "    figure_bestLIS = \"figures/LISscore.png\"\n",
    "    figure_bestAA = \"figures/AA_best_interacting_residues.png\"\n",
    "\n",
    "    from pptx.util import Inches\n",
    "    slide.placeholders[11].insert_picture(figure_bestAA, )\n",
    "    slide.placeholders[12].insert_picture(figure_bestLIS)\n",
    "    slide.placeholders[13].insert_picture(figure_LIS)\n",
    "        \n",
    "\n",
    "def add_contact_maps_slide(prs, model):\n",
    "    prot = model.split(\"_\")[0]\n",
    "    target = model.split(\"_\")[1]\n",
    "    \n",
    "    slide_layout = prs.slide_layouts[4]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=f\"Contacts between {prot} and {target}\"\n",
    "    slide.placeholders[11].insert_picture(f\"{model}_contacts.png\")\n",
    "    note = f\"\"\" DEFINITION OF THE CONTACTS : \n",
    "a contact is define as one amino acid beeing at a distance of less than {CUTOFF_DISTANCE} nm from another amino acid.\n",
    "Contacts between 2 amino acids are counted only one time per model.\n",
    "\n",
    "Higher value means more contacts between the 2 amino acids\n",
    "\"\"\"\n",
    "    add_notes(slide, note)\n",
    "\n",
    "\n",
    "#----------------------\n",
    "\n",
    "add_title_slide(prs, TITLE_REPPORT, \"AlphaFold repport modelling\")\n",
    "\n",
    "add_section(prs,\"Results per models\")\n",
    "\n",
    "for model in models_name:\n",
    "    os.chdir(\"predictions/\"+model)\n",
    "    add_models_result_slide(prs, model, results)\n",
    "    add_contact_maps_slide(prs, model)\n",
    "    add_all_models(prs, model)\n",
    "    os.chdir(WORKDIR)\n",
    "\n",
    "\n",
    "add_section(prs,\"Comparison between models\")\n",
    "add_slide_interactions(prs)\n",
    "\n",
    "add_section(prs,\"Models Parameters\")\n",
    "add_methodology_slide(prs, models_parameters)\n",
    "\n",
    "add_section(prs,\"Conclusion\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instert \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the PowerPoint\n",
    "output_file = f'{WORKDIR}/repport.pptx'\n",
    "prs.save(output_file)\n",
    "print(f\"PowerPoint saved to {output_file}\")\n",
    "os.chdir(WORKDIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
