{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import af2_analysis as af2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TITLE_REPPORT = \"Modelling repport ORF2 fullLength vs. TKB1\"\n",
    "WORKDIR = '/mnt/c/WORK/hev/loan/ORF2_fulllength_TKB1/'\n",
    "CUTOFF_DISTANCE = 0.5\n",
    "MINIMUM_CONTACTS = 5\n",
    "SELECTION1 = \"chainid 0\"\n",
    "SELECTION2 = \"chainid 1 or chainid 2\"\n",
    "CUTOFF_CONTACTS_GRAPH = 20\n",
    "GENERATE_ALL_PAE_SCRIPT = \"~/CNRS2022/dev/AFToolkit/PAE/generate_all_pae.py\"\n",
    "PPTX_TEMPLATE = \"~/CNRS2022/dev/AFToolkit/misc/template_repporting.pptx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "folders = [ f.path for f in os.scandir(\"predictions/\") if f.is_dir() ]\n",
    "\n",
    "for folder in folders: \n",
    "    os.system(f\"python {GENERATE_ALL_PAE_SCRIPT} -s N -f {folder}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Samuel's tool wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "from af2_analysis import analysis\n",
    "from af2_analysis import docking\n",
    "\n",
    "\n",
    "def plot_single_PAE(data, index, ax=None, cmap = 'bwr'):\n",
    "    if ax == None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    \n",
    "    json_file = data.df[\"json\"][index]\n",
    "    with open(json_file) as f:\n",
    "        json_data = json.load(f)\n",
    "\n",
    "    query = data.df.iloc[index][\"query\"]\n",
    "    \n",
    "    borders = data.chain_length[query]\n",
    "    res_max = sum(borders)\n",
    "    \n",
    "    PAE = json_data[\"pae\"]\n",
    "\n",
    "    ax.imshow(PAE, cmap=cmap,\n",
    "        vmin=0.0,\n",
    "        interpolation='nearest',\n",
    "        vmax=30.0,)\n",
    "\n",
    "    ax.hlines(\n",
    "            np.cumsum(borders[:-1]) - 0.5,\n",
    "            xmin=-0.5,\n",
    "            xmax=res_max,\n",
    "            colors=\"black\",\n",
    "        )\n",
    "\n",
    "    ax.vlines(\n",
    "            np.cumsum(borders[:-1]) - 0.5,\n",
    "            ymin=-0.5,\n",
    "            ymax=res_max,\n",
    "            colors=\"black\",\n",
    "        )\n",
    "\n",
    "    ax.set_xlim(-0.5, res_max - 0.5)\n",
    "    ax.set_ylim(res_max - 0.5, -0.5)\n",
    "\n",
    "    modelNumber = data.df[\"model\"][index]\n",
    "    ax.set_title(f\"Rank {modelNumber}\")\n",
    "    return ax\n",
    "        \n",
    "        \n",
    "        \n",
    "def save_all_PAE(data, save=True):\n",
    "\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20, 4))\n",
    "    for i in range(len(data.df)):\n",
    "        plot_single_PAE(data, i, cmap='bwr', ax=axes[i])\n",
    "        \n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if save == True:\n",
    "        plt.savefig(f\"{data.dir}/PAE.png\", dpi=300)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def save_plddt(data, ax=None):\n",
    "    if ax==None:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 4))\n",
    "    for i in range(len(data.df)):\n",
    "\n",
    "        query = data.df.iloc[i][\"query\"]\n",
    "        \n",
    "        borders = data.chain_length[query]\n",
    "        res_max = sum(borders)\n",
    "\n",
    "        plddt = data.get_plddt(i)\n",
    "        ax.plot(plddt, label=f\"Model {i}\", linewidth=0.5)\n",
    "        \n",
    "        ax.vlines(\n",
    "                np.cumsum(borders[:-1]) - 0.5,\n",
    "                ymin=-0.5,\n",
    "                ymax=100,\n",
    "                colors=\"black\",\n",
    "            )\n",
    "        \n",
    "        ax.set_ylim(0,100)\n",
    "\n",
    "        #add legend for every plot, on the side\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{data.dir}/plddt.png\", dpi=300)\n",
    "\n",
    "import re\n",
    "\n",
    "def extract_rank(text):\n",
    "    # Use a regular expression to find the rank number in the format \"_rank_XXX_\"\n",
    "    match = re.search(r'_rank_(\\d+)_', text)\n",
    "    if match:\n",
    "        return int(match.group(1))  # Convert the extracted rank to an integer\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_all_data(workdir):\n",
    "    os.chdir(workdir)\n",
    "\n",
    "    folders = [f for f in glob.glob(\"*\") if os.path.isdir(f)]\n",
    "\n",
    "    print(folders)\n",
    "\n",
    "    errors=[]\n",
    "    list_of_scores=[]\n",
    "    models_list = {}\n",
    "\n",
    "    for model in tqdm(folders):\n",
    "        \n",
    "        try:\n",
    "            data = af2.Data(model+\"/\", verbose=False)\n",
    "        except Exception as e:\n",
    "            errors.append(model)\n",
    "            print(f\"Error occurred for model {model}: {str(e)}\")\n",
    "            continue\n",
    "        print(model)\n",
    "        \n",
    "        try:\n",
    "            analysis.pdockq(data, verbose=False)\n",
    "        except:\n",
    "            print(\"pdockQ failed\")\n",
    "        try:\n",
    "            analysis.pdockq2(data, verbose=False)\n",
    "        except:\n",
    "            print(\"pdockq2 failed\")\n",
    "\n",
    "        try:\n",
    "            analysis.mpdockq(data, verbose=False)\n",
    "        except:\n",
    "            print(\"mpdockq failed\")\n",
    "            \n",
    "        try:\n",
    "            analysis.inter_chain_pae(data, verbose=False)\n",
    "        except:\n",
    "            print(\"inter_chain_pae failed\")\n",
    "\n",
    "        try:\n",
    "            analysis.LIS_matrix(data, verbose=False)\n",
    "        except:\n",
    "            print(\"LIS_matrix failed\")\n",
    "\n",
    "        try:\n",
    "            docking.LIS_pep(data, verbose=False)\n",
    "        except:\n",
    "            print(\"LIS PEP failed\")\n",
    "\n",
    "        if \"rank\" not in data.df.columns:\n",
    "            #add the rank from PDB name in the dataframe\n",
    "            data.df[\"rank\"] = data.df[\"pdb\"].apply(extract_rank)\n",
    "\n",
    "        \n",
    "        for i in range(5):\n",
    "            \n",
    "            json_file = data.df[\"json\"][i]\n",
    "            with open(json_file) as f:\n",
    "                json_data = json.load(f)\n",
    "            pae_array = json_data[\"pae\"]\n",
    "\n",
    "            pae_mean = np.mean(pae_array)\n",
    "            plddt = data.get_plddt(i)\n",
    "            plddt_mean = np.mean(plddt)\n",
    "\n",
    "            data.df.loc[i, \"pae_mean\"] = pae_mean\n",
    "            data.df.loc[i, \"plddt_mean\"] = plddt_mean\n",
    "            \n",
    "        name = str(data.df.iloc[0][\"query\"])\n",
    "        models_list[name] = data\n",
    "\n",
    "        list_of_scores.append(data.df)\n",
    "    \n",
    "    results = pd.concat(list_of_scores)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(WORKDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_all_data(f\"{WORKDIR}/predictions\")\n",
    "results[\"interLIS\"] = results[\"LIS\"].apply(lambda x: np.mean([x[0][1], x[1][0]]))\n",
    "results[\"LIS_average\"] = results.groupby(\"query\")[\"interLIS\"].transform(\"mean\")\n",
    "results[\"LIS_std\"] = results.groupby(\"query\")[\"interLIS\"].transform(\"std\")\n",
    "results.query(\"rank == 1\").sort_values(by=\"LIS_pep_rec\", ascending=False).to_excel(\"first_ranked_models.xlsx\")\n",
    "results.query(\"rank == 1\").sort_values(by=\"LIS_pep_rec\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contact analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mdtraj as md\n",
    "from collections import defaultdict\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def get_residue_label(traj, atom_index, add=0, with_chain = False):\n",
    "    resname = traj.topology.atom(atom_index).residue.name\n",
    "    resid = traj.topology.atom(atom_index).residue.resSeq + add\n",
    "    chain = chr(ord('A') + traj.topology.atom(atom_index).residue.chain.index)\n",
    "    if with_chain:\n",
    "        return f\"{resname}-{resid}-{chain}\"\n",
    "    else:\n",
    "        return f\"{resname} {resid}\"\n",
    "\n",
    "def compute_contacts(pdbs, selection1, selection2, add1, add2, cutoff=0.4, with_chain=False):\n",
    "    traj = md.load(pdbs, top=pdbs[0])\n",
    "\n",
    "    chainA = traj.topology.select(selection1)\n",
    "    chainB = traj.topology.select(selection2)\n",
    "\n",
    "    chainAB = np.concatenate((chainA,chainB))\n",
    "\n",
    "    contactsB = md.compute_neighbors(traj, cutoff, query_indices=chainA, haystack_indices=chainB)\n",
    "    contactsA = md.compute_neighbors(traj, cutoff, query_indices=chainB, haystack_indices=chainA)\n",
    "\n",
    "\n",
    "    contacts_linearB = [item for sublist in contactsB for item in sublist]\n",
    "    contacts_linearA = [item for sublist in contactsA for item in sublist]\n",
    "    contacts_atoms = np.unique(np.concatenate((contacts_linearB, contacts_linearA)))\n",
    "\n",
    "    subtraj = traj.atom_slice(contacts_atoms)\n",
    "\n",
    "    subtraj.save_pdb(\"subtraj.pdb\")\n",
    "\n",
    "    #get the number of chains \n",
    "    nchains = subtraj.top.n_chains\n",
    "\n",
    "\n",
    "\n",
    "    chain1_atoms = subtraj.topology.select(selection1)\n",
    "    chain2_atoms = subtraj.topology.select(selection2)\n",
    "    #parwise combinations of 2 chains\n",
    "    chain1_chain2 = np.array(np.meshgrid(chain1_atoms, chain2_atoms)).T.reshape(-1, 2)\n",
    "    # all_distances = md.compute_contacts(subtraj, contacts='all')\n",
    "    all_distances = md.compute_distances(subtraj, atom_pairs=chain1_chain2)\n",
    "\n",
    "    nframes = all_distances.shape[0]\n",
    "    npair = all_distances.shape[1]\n",
    "\n",
    "    # Create a dictionary to store the shortest distances between residues for each frame\n",
    "    shortest_distances = defaultdict(lambda: defaultdict(lambda: float('inf')))\n",
    "\n",
    "    for i in range(nframes):\n",
    "        for j in range(npair):\n",
    "            dist = all_distances[i, j]\n",
    "            pair = chain1_chain2[j]\n",
    "            res1 = get_residue_label(subtraj, pair[0], add=add1, with_chain=with_chain)\n",
    "            res2 = get_residue_label(subtraj, pair[1], add=add2, with_chain=with_chain)\n",
    "            \n",
    "            # Check if the current distance is shorter than the stored shortest distance for the current frame\n",
    "            if dist < shortest_distances[i][(res1, res2)]:\n",
    "                shortest_distances[i][(res1, res2)] = dist\n",
    "\n",
    "\n",
    "    # Convert the dictionary to a DataFrame with one column per frame\n",
    "    df_shortest_distances = pd.DataFrame(shortest_distances)\n",
    "\n",
    "    # set multilevel index names to \"res1\" and \"res2\"\n",
    "    df_shortest_distances.index.names = [\"res1\", \"res2\"]\n",
    "\n",
    "    return df_shortest_distances\n",
    "\n",
    "def plot_contacts(df, cutoff, outputname=\"output.png\", minimum_contacts=3, xaxis_label=\"selection 1\", yaxis_label=\"selection 2\", title=\"\", vmax=None):\n",
    "\n",
    "    ncol = len(df.columns)\n",
    "    def count_values_below_threshold(row, threshold=0.4):\n",
    "        return (row < threshold).sum()\n",
    "    count_table  = df.apply(lambda x: (x < cutoff).sum(), axis=1).unstack(fill_value=0)\n",
    "\n",
    "    # Trier les colonnes\n",
    "    numeric_part_columns = count_table.columns.to_series().str.extract('(\\d+)').astype(int)\n",
    "    sorted_columns = numeric_part_columns[0].argsort()\n",
    "    count_table = count_table.iloc[:, sorted_columns]\n",
    "\n",
    "    # Trier l'index\n",
    "    numeric_part_index = count_table.index.to_series().str.extract('(\\d+)').astype(int)\n",
    "    sorted_index = numeric_part_index[0].argsort()\n",
    "    count_table = count_table.iloc[sorted_index]\n",
    "\n",
    "    #keep only the values where the number of contacts is > 4\n",
    "    count_table = count_table[count_table >= minimum_contacts].dropna(how='all', axis=0).dropna(how='all', axis=1)\n",
    "    \n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12,10))\n",
    "    if vmax == None:\n",
    "        vmax = count_table.max().max()\n",
    "    g = sns.heatmap(count_table, cmap=\"Blues\", annot=False,xticklabels=True, yticklabels=True, ax=ax, vmin=0, vmax=vmax)\n",
    "    \n",
    "    #Set xticklabels to display EVERY LABELS\n",
    "    g.set_xticks(np.arange(0.5, len(count_table.columns), 1))\n",
    "    g.set_xlabel(xaxis_label)\n",
    "    g.set_ylabel(yaxis_label)\n",
    "    g.set_xticklabels(g.get_xticklabels(), rotation=90, horizontalalignment='center', fontsize=8)\n",
    "    \n",
    "    \n",
    "    g.set_title(title)\n",
    "    plt.tight_layout()\n",
    "    g.figure.savefig(outputname)\n",
    "    \n",
    "\n",
    "    return count_table.replace(np.nan,0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_name = results[\"query\"].unique()\n",
    "\n",
    "output_countact_table = {}\n",
    "for model in models_name:\n",
    "    #specific cases\n",
    "    if model == \"ORF2-75-100xNter_TKB1x2\":\n",
    "        sel1 = \"chainid 0 or chainid 1\"\n",
    "        sel2 = \"chainid 2 or chainid 3\"\n",
    "    else: \n",
    "        sel1 = SELECTION1\n",
    "        sel2 = SELECTION2\n",
    "\n",
    "    xaxis = model.split(\"_\")[1]\n",
    "    yaxis = model.split(\"_\")[0]\n",
    "\n",
    "    xsplit = xaxis.split(\"-\")\n",
    "    ysplit = yaxis.split(\"-\")\n",
    "\n",
    "    if len(xsplit) > 0:\n",
    "        try:\n",
    "            decalX = int(xsplit[1])-1\n",
    "        except:\n",
    "            decalX = 0\n",
    "    else:\n",
    "        decalX = 0\n",
    "    if len(ysplit) > 0:\n",
    "        try:\n",
    "            decalY = int(ysplit[1])-1\n",
    "        except:\n",
    "            decalY = 0\n",
    "    else:\n",
    "        decalY = 0\n",
    "\n",
    "    pdbs= results.query(\"query == @model\")[\"pdb\"].values\n",
    "\n",
    "\n",
    "    df_shortest_distances = compute_contacts(pdbs, sel1, sel2, decalY, decalX, CUTOFF_DISTANCE, with_chain=False)\n",
    "    ct = plot_contacts(df_shortest_distances, \n",
    "              CUTOFF_DISTANCE,\n",
    "              xaxis_label=xaxis,\n",
    "              yaxis_label=yaxis, \n",
    "              minimum_contacts=MINIMUM_CONTACTS,\n",
    "              title=f\"Number of contacts among the 15 models (minimum contact = {MINIMUM_CONTACTS})\",\n",
    "              outputname=f\"{model}/{model}_contacts.png\",\n",
    "              vmax=15)\n",
    "    output_countact_table[model] = ct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import os\n",
    "os.chdir(WORKDIR)\n",
    "\n",
    "#test if figures folder exist\n",
    "if not os.path.exists(\"figures\"):\n",
    "    os.makedirs(\"figures\")\n",
    "best = results.query(\"rank == 1\")\n",
    "#Seaborn boxplot of \"InterLIS\" for each query\n",
    "fig,ax = plt.subplots(figsize=(10,5.3))\n",
    "g = sns.stripplot(x=\"query\", y=\"interLIS\", data=results.sort_values(by=\"LIS_average\", ascending=False), ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"LIS scores for each query\")\n",
    "plt.ylabel(\"LIS score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/LISscore.png\", dpi=300)\n",
    "\n",
    "#seaborn barplot of interLIS for best models\n",
    "fig,ax = plt.subplots(figsize=(10,5.3))\n",
    "g = sns.barplot(x=\"query\", y=\"interLIS\", data=best.sort_values(by=\"interLIS\", ascending=False), ax=ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Best LIS scores for each query\")\n",
    "plt.ylabel(\"LIS score\")\n",
    "plt.xlabel(\"Model\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/best_LISscore.png\", dpi=300)\n",
    "\n",
    "\n",
    "contact_sums = [x.sum(axis=1) for x in output_countact_table.values()]\n",
    "number_of_contact = pd.concat(contact_sums, axis=1).sum(axis=1).sort_values(ascending=False)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "# barplot with seaborn, vertical, with a cutoff value above 25\n",
    "fig, ax = plt.subplots(figsize=(8.1, 10))\n",
    "#Keep only the values where the number of contacts is > 25\n",
    "dataplot = number_of_contact[number_of_contact > CUTOFF_CONTACTS_GRAPH]\n",
    "g = sns.barplot(y=dataplot.index, x=dataplot.values, ax=ax)\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "plt.title(f\"Most interacting ORF2P residues (number of contacts minimum = {CUTOFF_CONTACTS_GRAPH})\")\n",
    "plt.xlabel(f\"Number of contacts among all models \")\n",
    "plt.ylabel(\"Residue\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"figures/AA_best_interacting_residues.png\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "def get_models_parameters(jsonfile):\n",
    "    with open(jsonfile) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    return data\n",
    "\n",
    "models_parameters = get_models_parameters(f\"{WORKDIR}/predictions/config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt  # For size adjustment\n",
    "\n",
    "\n",
    "\n",
    "os.chdir(WORKDIR)\n",
    "# Create a PowerPoint presentation from a template\n",
    "template_path = PPTX_TEMPLATE  # Specify your template path\n",
    "prs = Presentation(template_path)\n",
    "\n",
    "# Or if you want to set the aspect ratio to 16:9 manually, you can create a blank presentation and set the size\n",
    "# prs = Presentation()\n",
    "# prs.slide_width = Inches(13.33)  # 16:9 ratio width\n",
    "# prs.slide_height = Inches(7.5)   # 16:9 ratio height\n",
    "\n",
    "#Add a title slide\n",
    "\n",
    "\n",
    "def add_title_slide(prs, title_input, subtitle_text):\n",
    "    slide_layout = prs.slide_layouts[0]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    subtitle = slide.placeholders[1]\n",
    "\n",
    "    title.text = title_input\n",
    "    subtitle.text = subtitle_text\n",
    "\n",
    "\n",
    "\n",
    "def add_methodology_slide(prs, models_parameters):\n",
    "    # Create a new slide with a title and content layout\n",
    "    slide_layout = prs.slide_layouts[1]  # Assuming this layout fits your template\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    title = slide.shapes.title\n",
    "    content = slide.shapes.placeholders[1]\n",
    "\n",
    "\n",
    "    # Set the title\n",
    "    title.text = \"Methodology\"\n",
    "    title.text_frame.paragraphs[0].font.size = Pt(36)  # Set the font size for the title\n",
    "\n",
    "    # Add bullet points with adjustable font size\n",
    "    bullet_points = [\n",
    "        f'ColabFold Version: {models_parameters[\"version\"]} ({models_parameters[\"commit\"]})',\n",
    "        f'AlphaFold Model: {models_parameters[\"model_type\"]}',\n",
    "        f'MSA mode\": {models_parameters[\"msa_mode\"]}',\n",
    "        f'Number of Queries: {models_parameters[\"num_queries\"]}',\n",
    "        f'Number of Models per Query: {models_parameters[\"num_models\"]*models_parameters[\"num_seeds\"]}',\n",
    "        \n",
    "    ]\n",
    "\n",
    "    for point in bullet_points:\n",
    "        p = content.text_frame.add_paragraph()\n",
    "        p.text = point\n",
    "        p.font.size = Pt(20)  # Adjust the font size for bullet points\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_pymol_figure(pdbfile, pymolpath=\"/home/thibault/miniconda3/bin/pymol\"):\n",
    "    pdbfile = os.path.basename(pdbfile)\n",
    "    pymolcmd = f'''as cartoon\n",
    "orient\n",
    "spectrum b, rainbow_rev, minimum=10, maximum=90\n",
    "\n",
    "alias raysetting, set ambient, 0.5; set specular, 0; set ray_trace_mode, 1; set ray_trace_gain, 0.01; set antialias,2; set ray_trace_color, black\n",
    "raysetting\n",
    "\n",
    "scene plddt, store\n",
    "png model1_plddt.png, ray=1, width=1080\n",
    "\n",
    "util.cbc\n",
    "scene bychain, store\n",
    "png model1_bychain.png, ray=1, width=1080\n",
    "'''\n",
    "    os.system(f\"{pymolpath} -c {pdbfile} -d '{pymolcmd}'\")\n",
    "\n",
    "    pymol_allfigures_cmd = f'''\n",
    "models = cmd.get_object_list()\n",
    "cmd.alignto(models[0], \"super\")\n",
    "\n",
    "orient\n",
    "util.cbc\n",
    "bgwhite\n",
    "draw 2160\n",
    "png all_models_bychain.png, width=1080\n",
    "'''\n",
    "    os.system(f\"{pymolpath} -c *.pdb -d '{pymol_allfigures_cmd}'\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_section(prs, title):\n",
    "    slide_layout = prs.slide_layouts[6]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=title\n",
    "\n",
    "def add_notes(slide, notes):\n",
    "    slide.notes_slide.notes_text_frame.text = notes\n",
    "\n",
    "def add_models_result_slide(prs, model_name, results_dataframe):\n",
    "    ## Check all placeholders in the current slide\n",
    "    #for placeholder in slide.placeholders:\n",
    "    #    print(f\"Placeholder index: {placeholder.placeholder_format.idx}, Placeholder type: {placeholder.placeholder_format.type}\")  \n",
    "\n",
    "    slide_layout = prs.slide_layouts[2]\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text = f\"Model {model_name}\"\n",
    "\n",
    "    #Add a picture of the PAE\n",
    "    slide.placeholders[10].insert_picture(\"all_PAE.png\")\n",
    "    slide.placeholders[11].insert_picture(f\"{model}_coverage.png\")\n",
    "    slide.placeholders[12].insert_picture(f\"{model}_plddt.png\")\n",
    "\n",
    "    #Generating pymol figure, if not exist\n",
    "    img_model_plddt = \"model1_plddt.png\"\n",
    "    img_model_bychain = \"model1_bychain.png\"\n",
    "    # Get unique values of the column \"query\"\n",
    "    if not os.path.exists(img_model_plddt) or not os.path.exists(img_model_bychain) or not os.path.exists(\"all_models_bychain.png\"):\n",
    "        try:\n",
    "            pdbfile = results_dataframe.query(\"query == @model_name and rank == 1\")[\"pdb\"].values[0]\n",
    "        except:\n",
    "            print(results_dataframe.query(\"query == @model_name\"))\n",
    "            1/0\n",
    "        generate_pymol_figure(pdbfile)\n",
    "\n",
    "    slide.placeholders[13].insert_picture(img_model_plddt)\n",
    "    slide.placeholders[14].insert_picture(img_model_bychain)\n",
    "\n",
    "    note = \"\"\"DEFINITIONS OF THE METRICS \n",
    "- The pLDDT Score is a confidence score for each residue in the model. It ranges from 0 to 100, where higher scores indicate higher confidence. \n",
    "- The coverage plot shows the number of sequence in the multiple sequence aligment for each amino acid (Higher the better for the modelling). The colors depends sequence idendity. \n",
    "- PAE stands for \"Predicted Aligned Error\". This metric is a measure of the deviation between the predicted model and the experimental structure. Lower values are better. Low values coldspots between residues in chains A and B could indicate potential interaction sites.\n",
    "\"\"\"\n",
    "\n",
    "    add_notes(slide, note)\n",
    "\n",
    "def add_all_models(prs, model_name):\n",
    "    slide_layout = prs.slide_layouts[5]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text = f\"Model {model_name} - All models\"\n",
    "\n",
    "    imgfile = \"all_models_bychain.png\"\n",
    "\n",
    "    slide.placeholders[13].insert_picture(imgfile)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def add_slide_interactions(prs):\n",
    "    slide_layout = prs.slide_layouts[3]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=\"Interactions between MSN and other targets\"\n",
    "\n",
    "    figure_LIS = \"figures/LISscore.png\"\n",
    "    figure_bestLIS = \"figures/best_LISscore.png\"\n",
    "    figure_bestAA = \"figures/AA_best_interacting_residues.png\"\n",
    "\n",
    "    from pptx.util import Inches\n",
    "    slide.placeholders[11].insert_picture(figure_bestAA, )\n",
    "    slide.placeholders[12].insert_picture(figure_bestLIS)\n",
    "    slide.placeholders[13].insert_picture(figure_LIS)\n",
    "        \n",
    "\n",
    "def add_contact_maps_slide(prs, model):\n",
    "    prot = model.split(\"_\")[0]\n",
    "    target = model.split(\"_\")[1]\n",
    "    \n",
    "    slide_layout = prs.slide_layouts[4]  # Title layout\n",
    "    slide = prs.slides.add_slide(slide_layout)\n",
    "    slide.shapes.title.text=f\"Contacts between {prot} and {target}\"\n",
    "    slide.placeholders[11].insert_picture(f\"{model}_contacts.png\")\n",
    "    note = f\"\"\" DEFINITION OF THE CONTACTS : \n",
    "a contact is define as one amino acid beeing at a distance of less than {CUTOFF_DISTANCE} nm from another amino acid.\n",
    "Contacts between 2 amino acids are counted only one time per model.\n",
    "\n",
    "Higher value means more contacts between the 2 amino acids\n",
    "\"\"\"\n",
    "    add_notes(slide, note)\n",
    "\n",
    "\n",
    "#----------------------\n",
    "\n",
    "add_title_slide(prs, TITLE_REPPORT, \"AlphaFold repport modelling\")\n",
    "\n",
    "add_section(prs,\"Results per models\")\n",
    "\n",
    "for model in models_name:\n",
    "    os.chdir(\"predictions/\"+model)\n",
    "    add_models_result_slide(prs, model, results)\n",
    "    add_contact_maps_slide(prs, model)\n",
    "    add_all_models(prs, model)\n",
    "    os.chdir(WORKDIR)\n",
    "\n",
    "\n",
    "add_section(prs,\"Comparison between models\")\n",
    "add_slide_interactions(prs)\n",
    "\n",
    "add_section(prs,\"Models Parameters\")\n",
    "add_methodology_slide(prs, models_parameters)\n",
    "\n",
    "add_section(prs,\"Conclusion\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Instert \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the PowerPoint\n",
    "output_file = f'{WORKDIR}/repport.pptx'\n",
    "prs.save(output_file)\n",
    "print(f\"PowerPoint saved to {output_file}\")\n",
    "os.chdir(WORKDIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "afanalysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
